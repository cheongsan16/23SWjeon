{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheongsan16/23SWjeon/blob/main/age_gender_pred_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XimomqrjAy64",
        "outputId": "d1681649-a1d0-4f97-e7fc-f77a7313f74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "cTA4Yq1Gt9Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def extract_age_and_gender_from_filename(filename):\n",
        "    parts = filename.split('_')\n",
        "    age = int(parts[0])\n",
        "    gender = int(parts[1])\n",
        "    return age, gender"
      ],
      "metadata": {
        "id": "_hqvOGaJrc5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나이로 폴더 재구성\n",
        "import shutil\n",
        "\n",
        "# 원본 이미지 파일이 위치한 폴더 경로\n",
        "input_folder = '/content/drive/MyDrive/crop_part1 (1)'\n",
        "\n",
        "# 새로운 카테고리로 이미지를 저장할 폴더 경로\n",
        "output_folder = '/content/drive/MyDrive/age_images'\n",
        "\n",
        "# 나이 범주\n",
        "age_categories = [(0, 2), (3, 5), (6, 12), (13, 18),(19, 24), (25, 35), (36, 45), (46, 60), (61, 80), (81, 120)]\n",
        "\n",
        "# 새로운 카테고리로 이미지를 저장하기 위한 폴더를 생성.\n",
        "for age_range in age_categories:\n",
        "  age_folder_name = f\"{age_range[0]}_{age_range[1]}\"\n",
        "  category_folder = os.path.join(output_folder, age_folder_name)\n",
        "  os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "# input_folder에 있는 모든 이미지 파일들을 처리.\n",
        "for filename in os.listdir(input_folder):\n",
        "    # 파일 이름에서 나이정보를 추출.\n",
        "    parts = filename.split('_')\n",
        "    age = int(parts[0])\n",
        "\n",
        "    # 나이에 따라 새로운 카테고리 폴더를 선택\n",
        "    for age_range in age_categories:\n",
        "        if age_range[0] <= age <= age_range[1]:\n",
        "            age_folder_name = f\"{age_range[0]}_{age_range[1]}\"\n",
        "            break\n",
        "\n",
        "    category_folder = os.path.join(output_folder, age_folder_name)\n",
        "\n",
        "    # 이미지 파일을 새로운 카테고리 폴더로 복사.\n",
        "    src_path = os.path.join(input_folder, filename)\n",
        "    dst_path = os.path.join(category_folder, filename)\n",
        "    shutil.copyfile(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "Kq5iPcaw9iqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 성별로 폴더 재구성\n",
        "# 원본 이미지 파일이 위치한 폴더 경로\n",
        "input_folder = '/content/drive/MyDrive/crop_part1 (1)'\n",
        "\n",
        "# 새로운 카테고리로 이미지를 저장할 폴더 경로\n",
        "output_folder = '/content/drive/MyDrive/gender_images'\n",
        "\n",
        "# 성별 범주\n",
        "gender_categories = [0, 1, 3]\n",
        "\n",
        "# 새로운 카테고리로 이미지를 저장하기 위한 폴더를 생성.\n",
        "for gender in gender_categories:\n",
        "  gender_folder_name = f\"{gender}\"\n",
        "  category_folder = os.path.join(output_folder, gender_folder_name)\n",
        "  os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "# input_folder에 있는 모든 이미지 파일들을 처리.\n",
        "for filename in os.listdir(input_folder):\n",
        "    # 파일 이름에서 성별 정보를 추출.\n",
        "    parts = filename.split('_')\n",
        "    gender = int(parts[1])\n",
        "\n",
        "    # 성별에 따라 새로운 카테고리 폴더를 선택.\n",
        "    gender_folder_name = f\"{gender}\"\n",
        "    category_folder = os.path.join(output_folder, gender_folder_name)\n",
        "\n",
        "    # 이미지 파일을 새로운 카테고리 폴더로 복사.\n",
        "    src_path = os.path.join(input_folder, filename)\n",
        "    dst_path = os.path.join(category_folder, filename)\n",
        "    shutil.copyfile(src_path, dst_path)"
      ],
      "metadata": {
        "id": "5Ulz_W_m9tKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 이미지 로드 및 전처리"
      ],
      "metadata": {
        "id": "jcRY65r_TGla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "BehR5csv99mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 200\n",
        "img_width = 200"
      ],
      "metadata": {
        "id": "f1dAWCeHU11t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 성별에 따른 데이터\n",
        "photo_directory = '/content/drive/MyDrive/gender_images'\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen = image_generator.flow_from_directory(directory=photo_directory,\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(img_height, img_width),\n",
        "                                                     classes = ['0','1'])"
      ],
      "metadata": {
        "id": "TDdLThgSXt9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6741c81-9daf-4dc3-d5e1-071ddcfc4a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9779 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성별 모델 생성\n",
        "model_gen = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # 출력 레이어 설정 (카테고리 개수)\n",
        "])\n",
        "\n",
        "# 성별 모델 컴파일\n",
        "model_gen.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 성별 모델 학습\n",
        "model_gen.fit(train_data_gen, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB3Gb7-D-NMp",
        "outputId": "cd9edc2d-529f-4568-857e-9871577bf739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "306/306 [==============================] - 713s 2s/step - loss: 0.5993 - accuracy: 0.7348\n",
            "Epoch 2/10\n",
            "306/306 [==============================] - 698s 2s/step - loss: 0.4161 - accuracy: 0.8050\n",
            "Epoch 3/10\n",
            "306/306 [==============================] - 696s 2s/step - loss: 0.3507 - accuracy: 0.8318\n",
            "Epoch 4/10\n",
            "306/306 [==============================] - 686s 2s/step - loss: 0.2852 - accuracy: 0.8717\n",
            "Epoch 5/10\n",
            "306/306 [==============================] - 685s 2s/step - loss: 0.2329 - accuracy: 0.8997\n",
            "Epoch 6/10\n",
            "306/306 [==============================] - 693s 2s/step - loss: 0.1654 - accuracy: 0.9333\n",
            "Epoch 7/10\n",
            "306/306 [==============================] - 685s 2s/step - loss: 0.1326 - accuracy: 0.9483\n",
            "Epoch 8/10\n",
            "306/306 [==============================] - 686s 2s/step - loss: 0.1012 - accuracy: 0.9612\n",
            "Epoch 9/10\n",
            "306/306 [==============================] - 681s 2s/step - loss: 0.0742 - accuracy: 0.9726\n",
            "Epoch 10/10\n",
            "306/306 [==============================] - 689s 2s/step - loss: 0.0615 - accuracy: 0.9798\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d8d5eecf760>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 저장할 폴더 경로 설정\n",
        "save_folder_path = '/content/drive/My Drive/Models/'\n",
        "\n",
        "# 모델 파일을 저장할 경로로 모델 저장\n",
        "model_gen.save(save_folder_path + '_gender_model.h5')"
      ],
      "metadata": {
        "id": "Gm5sx8ZR-VXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나이에 따른 데이터\n",
        "photo_directory = '/content/drive/MyDrive/age_images/age_images'\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_age_gen = image_generator.flow_from_directory(directory=photo_directory,\n",
        "                                                     batch_size=32,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(img_height, img_width),\n",
        "                                                     class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1qtJkFR-YoF",
        "outputId": "148e8c7f-5812-4aac-d96a-d6297917740e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9780 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 나이 모델 생성\n",
        "model_age = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')  # 출력 레이어 설정 (카테고리 개수)\n",
        "])\n",
        "\n",
        "# 나이 모델 컴파일\n",
        "model_age.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 나이 모델 학습\n",
        "model_age.fit(train_age_gen, epochs=10)"
      ],
      "metadata": {
        "id": "Ybm84WIfwI6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 저장할 폴더 경로 설정\n",
        "save_folder_path = '/content/drive/My Drive/Models/'\n",
        "\n",
        "# 모델 파일을 저장할 경로로 모델 저장\n",
        "model_age.save(save_folder_path + '_age_model_1.h5')"
      ],
      "metadata": {
        "id": "6m48kUSK-gBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_gender = load_model(\"C:\\\\Users\\\\82104\\\\PycharmProjects\\\\pythonProject\\\\_gender_model.h5\")\n",
        "model_age = load_model(\"C:\\\\Users\\\\82104\\\\PycharmProjects\\\\pythonProject\\\\_age_model_1.h5\")\n",
        "\n",
        "input_size = (200, 200, 3)\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# 성별과 나이 클래스\n",
        "gender_list = ['Male', 'Female']\n",
        "age_list = ['(0 ~ 2)','(3 ~ 5)','(6 ~ 12)','(13 ~ 18)', '(19 ~ 24)','(25 ~ 35)','(36 ~ 45)','(46 ~ 60)','(61 ~ 80)','(81 ~ 120)']\n",
        "\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # 영상 프레임 읽기\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    # 영상을 흑백으로 변환\n",
        "    #gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 얼굴 검출 수행\n",
        "    faces = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # 얼굴에 사각형 그리기\n",
        "    for (x, y, w, h) in faces:\n",
        "        # 얼굴 영역 추출\n",
        "        face_roi = frame[y:y + h, x:x + w]\n",
        "\n",
        "        # 입력 크기에 맞게 조절\n",
        "        face_roi = cv2.resize(face_roi, (input_size[1], input_size[0]))  # dsize 수정\n",
        "\n",
        "        # 모델에 입력하기 위해 차원 확장\n",
        "        face_roi = np.expand_dims(face_roi, axis=-1)\n",
        "        face_roi = np.expand_dims(face_roi, axis=0)\n",
        "\n",
        "        # 성별과 나이 예측\n",
        "        gender_prob = model_gender.predict(face_roi)\n",
        "        age_prob = model_age.predict(face_roi)\n",
        "        gender_label = gender_list[np.argmax(gender_prob[0])]\n",
        "        age_label = age_list[np.argmax(age_prob[0])]\n",
        "\n",
        "        # 영상에 결과 표시\n",
        "        label = f'{gender_label}, {age_label}'\n",
        "        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    # 화면에 영상 출력\n",
        "    cv2.imshow('Face Detection', frame)\n",
        "\n",
        "    # 'q' 키를 누르면 종료\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "XXwwrfL7v42w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}